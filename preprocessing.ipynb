{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "60c1035b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
        "\n",
        "def metadata_func(record, metadata):\n",
        "    metadata.update({\n",
        "        \"url\": record.get(\"url\", \"\"),\n",
        "        \"title\": record.get(\"title\", \"\"),\n",
        "        \"section\": record.get(\"section\", \"\"),\n",
        "        \"chunk_index\": record.get(\"chunk_index\", \"\"),\n",
        "    })\n",
        "    return metadata\n",
        "\n",
        "loader = DirectoryLoader(\n",
        "    \"./data\",\n",
        "    glob=\"attack_on_Titan_Namu*.jsonl\",\n",
        "    loader_cls=JSONLoader,\n",
        "    loader_kwargs={\n",
        "        \"jq_schema\": \".\",\n",
        "        \"json_lines\": True,\n",
        "        \"content_key\": \"text\",\n",
        "        \"metadata_func\": metadata_func,\n",
        "    },\n",
        ")\n",
        "\n",
        "document_list = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fec8d5f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 환경변수를 불러옴\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI에서 제공하는 Embedding Model을 활용해서 `chunk`를 vector화\n",
        "embedding = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df13b946",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_chroma import Chroma\n",
        "\n",
        "# # 데이터를 처음 저장할 때 \n",
        "# database = Chroma.from_documents(documents=document_list, embedding=embedding, collection_name='attack_on_Titan', persist_directory=\"./attack_on_Titan\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d39c86a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "database = Chroma(\n",
        "    collection_name=\"attack_on_Titan\",\n",
        "    persist_directory=\"./attack_on_Titan\",\n",
        "    embedding_function=embedding,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df47def",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "retriever = database.as_retriever(search_kwargs={\"k\": 3})\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "query = \"attack titan의 역대 계승자에 대해 알려줘. 이 때 각각의 인물에 대해 자세하게 설명해봐\"\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "prompt = f\"\"\"You are a helpful assistant. Use the context to answer.\n",
        "질문: {query}\n",
        "\n",
        "컨텍스트:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "response = llm.invoke(prompt)\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52001233",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Use the context to answer.\"),\n",
        "    (\"human\", \"질문: {input}\\n\\n컨텍스트:\\n{context}\")\n",
        "])\n",
        "\n",
        "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
        "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
        "\n",
        "ai_message = retrieval_chain.invoke({\"input\": query})\n",
        "ai_message[\"answer\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ae9c0f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"다음 내용은 제공된 문맥 내에 있는 정보만을 정리한 것입니다. 그 밖의 상세한 설명은 문맥에 없습니다 — 정보 부족.\\n\\n- 아홉 거인(Nine Titans)에 대한 설명은 별도의 '아홉 거인' 문서를 참고하라고 되어 있습니다.\\n- 계승자(또는 관련 인물)로 문맥에 나열된 항목들:\\n  - 아홉 거인, 가비 브라운, 나일 도크, 다이나 프리츠, 도트 픽시스, 레온하트 씨, 로그(진격의 거인), 로드 레이스(진격의 거인), 맘몬(진격의 거인), 바리스(진격의 거인), 벽의 거인, 아홉 거인, 오거(진격의 거인)\\n- 완전한 시조의 거인이 아홉 거인의 모든 힘을 사용할 수 있게 되면서 그 힘으로 모든 거인들의 경질화(갑옷화)를 해제하였다(문맥 내용). 그 결과 파라디 섬 세 방벽 내부의 초대형(벽 속) 거인들이 진격하여 방벽 주변 건물들이 무너지고 많은 사상자가 발생하기 시작했다는 기술이 있습니다.\\n- 아홉 거인의 능력들이 더해지면 더욱 강력해지며, 예로 갑옷의 경질화와 전퇴의 능력, 소유자의 극한 숙련도가 합쳐진 후반부의 진격(아마 특정 거인 또는 상태)은 아홉 거인들 중 상위권 전투력으로 평가된다고 문맥에 서술되어 있습니다.\\n- 추가 세부사항은 엘런 예거 문서의 8.1번 문단과 아홉 거인 문서를 참고하라고 명시되어 있습니다.\\n\\n위 외의 구체적 능력, 각 거인의 상세 설명 등은 문맥에 포함되어 있지 않습니다 — 정보 부족.\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RAG: reduce hallucination by stricter retrieval + prompt\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# retriever with more candidates + MMR for diversity\n",
        "retriever = database.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5, \"fetch_k\": 24}\n",
        ")\n",
        "\n",
        "query = \"아홉거인에 대해 자세하게 설명해줘\"\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# if retrieval is weak, fail fast\n",
        "if len(docs) < 2:\n",
        "    raise ValueError(\"컨텍스트가 부족합니다. 질문을 구체화하거나 k를 늘려주세요.\")\n",
        "\n",
        "context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "prompt = f\"\"\"You are a helpful assistant.\n",
        "Use ONLY the provided context.\n",
        "If the answer is not in the context, say \"정보 부족\".\n",
        "\n",
        "\n",
        "질문: {query}\n",
        "\n",
        "컨텍스트:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini\")\n",
        "response = llm.invoke(prompt)\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7874a92",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
