import streamlit as st
import tempfile
import os
import json

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

# 1. ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="RAG ì±—ë´‡", page_icon="ğŸ§©")
st.title("ğŸ§© ë°ì´í„° ê¸°ë°˜ RAG ì±—ë´‡")

# 2. ì‚¬ì´ë“œë°”: ì„¤ì • ë° íŒŒì¼ ì…ë ¥
with st.sidebar:
    st.header("ì„¤ì •")
    openai_api_key = st.text_input("OpenAI API Key", type="password")
    
    # ë™ë£Œê°€ ì¤€ íŒŒì¼ì„ ì—¬ê¸°ì„œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    uploaded_file = st.file_uploader("í¬ë¡¤ë§í•œ ë°ì´í„° íŒŒì¼(.jsonl) ì—…ë¡œë“œ", type=["jsonl"])
    st.markdown("---")
    st.caption("JSONL íŒŒì¼ì€ í•œ ì¤„ì— í•˜ë‚˜ì˜ JSON ë°ì´í„°ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

# 3. RAG í•µì‹¬ ë¡œì§ (ìºì‹± ì ìš©)
# @st.cache_resourceëŠ” ë²¡í„° DB ìƒì„±ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ, íŒŒì¼ì´ ë°”ë€Œì§€ ì•Šìœ¼ë©´ ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•´ë‘¡ë‹ˆë‹¤.
@st.cache_resource
def process_document(file_content):
    # Streamlit ì—…ë¡œë“œ íŒŒì¼ì€ ë°”ì´ë„ˆë¦¬ í˜•íƒœì´ë¯€ë¡œ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ ë¡œë“œ
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jsonl") as tmp_file:
        tmp_file.write(file_content)
        tmp_file_path = tmp_file.name

    try:
        documents = []
        # [í•µì‹¬ ìˆ˜ì •] íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ íŒŒì‹±
        with open(tmp_file_path, "r", encoding="utf-8") as f:
            for line in f:
                if not line.strip(): 
                    continue # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                
                try:
                    data = json.loads(line)
                    
                    # âš ï¸ ì¤‘ìš”: JSONì—ì„œ ì‹¤ì œ 'ë‚´ìš©'ì´ ë“¤ì–´ìˆëŠ” í‚¤(key) ì´ë¦„ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤.
                    # ì˜ˆ: {"title": "...", "content": "ë³¸ë¬¸ë‚´ìš©..."} ì´ë¼ë©´ "content"ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨.
                    # ì—¬ê¸°ì„œëŠ” 'text', 'content', 'body' ì¤‘ í•˜ë‚˜ë¥¼ ìë™ìœ¼ë¡œ ì°¾ë„ë¡ í–ˆìŠµë‹ˆë‹¤.
                    text_content = data.get("content") or data.get("text") or data.get("body")
                    
                    # ë§Œì•½ íŠ¹ì • í‚¤ê°€ ì—†ê³  ì „ì²´ë¥¼ ë‹¤ ì“°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
                    # text_content = json.dumps(data, ensure_ascii=False)

                    if text_content:
                        # LangChain Document ê°ì²´ ìƒì„± (ë©”íƒ€ë°ì´í„°ë„ ê°™ì´ ì €ì¥í•˜ë©´ ì¢‹ìŒ)
                        doc = Document(page_content=text_content, metadata=data)
                        documents.append(doc)
                except json.JSONDecodeError:
                    continue # ê¹¨ì§„ ë¼ì¸ì€ ë¬´ì‹œ

        # ë¬¸ì„œê°€ ë¹„ì–´ìˆìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
        if not documents:
            raise ValueError("JSONL íŒŒì¼ì—ì„œ ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤(Key) ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")

        # # B. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
        # text_splitter = RecursiveCharacterTextSplitter(
        #     chunk_size=1000,  # 1000ì ë‹¨ìœ„
        #     chunk_overlap=100 # ë¬¸ë§¥ ëŠê¹€ ë°©ì§€
        # )
        # splits = text_splitter.split_documents(documents)

        # C. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        # ì£¼ì˜: ìºì‹± í•¨ìˆ˜ ì•ˆì—ì„œëŠ” ì™¸ë¶€ ë³€ìˆ˜(api_key)ë¥¼ ì§ì ‘ ì“°ê¸°ë³´ë‹¤ íŒŒë¼ë¯¸í„°ë¡œ ë°›ê±°ë‚˜ ë‚´ë¶€ ì²˜ë¦¬í•´ì•¼ í•¨.
        # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ embeddings ê°ì²´ ìƒì„± ì‹œ í‚¤ê°€ í•„ìš”í•˜ë¯€ë¡œ, 
        # ì‹¤ì œë¡œëŠ” ì´ í•¨ìˆ˜ í˜¸ì¶œ ì „ì— í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ ì•ˆì „í•¨.
        embeddings = OpenAIEmbeddings(api_key=openai_api_key)
        vectorstore = FAISS.from_documents(documents, embeddings)
        
        return vectorstore

    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(tmp_file_path)

# 4. ë©”ì¸ ë¡œì§ ì‹¤í–‰
if uploaded_file and openai_api_key:
    # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ë©´ ë²¡í„° DB ìƒì„± (ë˜ëŠ” ìºì‹œëœ ê²ƒ ì‚¬ìš©)
    with st.spinner("ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            vector_store = process_document(uploaded_file.getvalue())
            st.success("ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ! ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: API Keyë¥¼ í™•ì¸í•˜ê±°ë‚˜ íŒŒì¼ ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.\n{e}")
            st.stop()
            
    # 5. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            # Retriever ì„¤ì •
            retriever = vector_store.as_retriever(search_kwargs={"k": 3}) # ê´€ë ¨ ë¬¸ì„œ 3ê°œ ì°¸ì¡°

            # LLM ì„¤ì •
            llm = ChatOpenAI(model="gpt-4o-mini", api_key=openai_api_key, temperature=0)

            # í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
            system_prompt = (
                "ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ë´‡ì…ë‹ˆë‹¤. "
                "Contextì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ê³ , ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”. "
                "\n\nContext:\n{context}"
            )
            
            prompt_template = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", "{input}")
            ])

            # Chain ì‹¤í–‰
            chain = create_stuff_documents_chain(llm, prompt_template)
            rag_chain = create_retrieval_chain(retriever, chain)
            
            response = rag_chain.invoke({"input": prompt})
            answer = response["answer"]
            
            st.markdown(answer)
            
        st.session_state.messages.append({"role": "assistant", "content": answer})

else:
    # ì´ˆê¸° í™”ë©´ ì•ˆë‚´
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•˜ê³ , ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")